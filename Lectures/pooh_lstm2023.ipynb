{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd3185b",
   "metadata": {},
   "source": [
    "# Language modeling with LSTM in Pytorch\n",
    "\n",
    "based on\n",
    "https://www.kdnuggets.com/2020/07/pytorch-lstm-text-generation-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d50e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "SEQUENCE_LENGTH = 15\n",
    "\n",
    "class PoohDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequence_length, device):\n",
    "        txt = open('../data/pooh1.txt').read()\n",
    "        txt += open('../data/pooh2.txt').read()\n",
    "        \n",
    "        self.words = word_tokenize(txt.lower())\n",
    "        #self.words = word_tokenize(txt)\n",
    "        \n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "        self.sequence_length = sequence_length\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        #return list(set(self.words))\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length], device=self.device),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1], device=self.device)\n",
    "        )\n",
    "        \n",
    "pooh_dataset = PoohDataset(SEQUENCE_LENGTH, device)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5203e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 15]) torch.Size([512, 15])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(pooh_dataset, batch_size=512)\n",
    "\n",
    "for x,y in dataloader:\n",
    "    print (x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b22a87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(2791, 100)\n",
       "  (lstm): LSTM(100, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=512, out_features=2791, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, dataset, device):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm_size = 512\n",
    "        self.embedding_dim = 100\n",
    "        self.num_layers = 2\n",
    "        self.device = device\n",
    "        \n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        \n",
    "        #Remember: state is a pair (h,c)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state_batched(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.lstm_size).to(self.device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.lstm_size).to(self.device))\n",
    "        \n",
    "    def init_state_unbatched(self):\n",
    "        return (torch.zeros(self.num_layers, self.lstm_size).to(self.device),\n",
    "                torch.zeros(self.num_layers, self.lstm_size).to(self.device))\n",
    "        \n",
    "        \n",
    "model = LSTMModel(pooh_dataset, device) \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6035ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, next_words=15):\n",
    "    model.eval()\n",
    "\n",
    "    words = word_tokenize(text.lower())\n",
    "    state_h, state_c = model.init_state_unbatched()\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([dataset.word_to_index[w] for w in words[i:]])\n",
    "        x = x.to(device)\n",
    "        \n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074d5f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 128, 'loss': 5.454943656921387}\n",
      "and then first 5. on rabbit had away say haven't to blue-bells that first or that him\n",
      "{'epoch': 1, 'batch': 128, 'loss': 5.040148735046387}\n",
      "and then you working owl before the reply to on to . '' if had come were\n",
      "{'epoch': 2, 'batch': 128, 'loss': 4.6826066970825195}\n",
      "and then written that he had anything a letters best things and did happy the room .\n",
      "{'epoch': 3, 'batch': 128, 'loss': 4.476163387298584}\n",
      "and then was piglet to answer , '' '' explained a point with as why it is\n",
      "{'epoch': 4, 'batch': 128, 'loss': 4.31948709487915}\n",
      "and then 's finished yet , his which once , which i he knew he said nothing\n",
      "{'epoch': 5, 'batch': 128, 'loss': 4.20013952255249}\n",
      "and then '' chapter face used . `` i wish , '' said pooh , `` if\n",
      "{'epoch': 6, 'batch': 128, 'loss': 4.091150760650635}\n",
      "and then and piglet knocked to his . `` nobody is , '' said pooh , only\n",
      "{'epoch': 7, 'batch': 128, 'loss': 3.954676389694214}\n",
      "and then piglet ; `` i 'll want the front yards he felt him ' a little\n",
      "{'epoch': 8, 'batch': 128, 'loss': 3.8460652828216553}\n",
      "and then he leant in which -- like a believe because misty and watch me , i\n",
      "{'epoch': 9, 'batch': 128, 'loss': 3.7391533851623535}\n",
      "and then he might blow about sad whether have there . piglet ; whether s. pup-pup-pup are\n",
      "{'epoch': 10, 'batch': 128, 'loss': 3.6290485858917236}\n",
      "and then we could know a house so , rabbit , `` i hope , '' said\n",
      "{'epoch': 11, 'batch': 128, 'loss': 3.5379207134246826}\n",
      "and then then he put pooh and kanga and `` is happy a bad position ? ''\n",
      "{'epoch': 12, 'batch': 128, 'loss': 3.439856767654419}\n",
      "and then while , and piglet said . `` i say , pooh coming in two door\n",
      "{'epoch': 13, 'batch': 128, 'loss': 3.361794948577881}\n",
      "and then it was listening in the forest , owl ? '' `` what 's all the\n",
      "{'epoch': 14, 'batch': 128, 'loss': 3.3003814220428467}\n",
      "and then not looking for a happy day , because he will be able to begin about\n",
      "{'epoch': 15, 'batch': 128, 'loss': 3.1935362815856934}\n",
      "and then began to bring that his own name ; and when you had wash that he\n",
      "{'epoch': 16, 'batch': 128, 'loss': 3.116309404373169}\n",
      "and then then `` of course , of course , there was a humble you put a\n",
      "{'epoch': 17, 'batch': 128, 'loss': 3.0390868186950684}\n",
      "and then we were getting busy pooh corner the south might know where it should , and\n",
      "{'epoch': 18, 'batch': 128, 'loss': 2.9745776653289795}\n",
      "and then i could stay a buzzing-noise . so things to be everybody about , but he\n",
      "{'epoch': 19, 'batch': 128, 'loss': 2.9309310913085938}\n",
      "and then not bounce about this , winnie-the-pooh ran after at them , so who know there\n",
      "{'epoch': 20, 'batch': 128, 'loss': 2.8525519371032715}\n",
      "and then we was got on the tracks , said piglet comfortingly , smiling up , he\n",
      "{'epoch': 21, 'batch': 128, 'loss': 2.7778420448303223}\n",
      "and then while i do love it again , why , they might shout it was a\n",
      "{'epoch': 22, 'batch': 128, 'loss': 2.6855995655059814}\n",
      "and then ringing him through both of it . because he could know when christopher robin had\n",
      "{'epoch': 23, 'batch': 128, 'loss': 2.6154510974884033}\n",
      "and then i wondered when you had had a letter-box viii . ago until at last he\n",
      "{'epoch': 24, 'batch': 128, 'loss': 2.541855812072754}\n",
      "and then pulled eeyore . piglet nudged pooh . eeyore was not quite knowing what they 'd\n",
      "{'epoch': 25, 'batch': 128, 'loss': 2.4572718143463135}\n",
      "and then there were no loud , '' and christopher robin had waited for a week which\n",
      "{'epoch': 26, 'batch': 128, 'loss': 2.3344433307647705}\n",
      "and then he lay something to come upon my late to him , but saw christopher robin\n",
      "{'epoch': 27, 'batch': 128, 'loss': 2.265109062194824}\n",
      "and then people leave it with a bank for an acrobat to each other place at the\n",
      "{'epoch': 28, 'batch': 128, 'loss': 2.1971871852874756}\n",
      "and then he us . `` it 's something in the ink-pot , right to be trying\n",
      "{'epoch': 29, 'batch': 128, 'loss': 2.153298854827881}\n",
      "and then pooh nodded home for a long time . `` you 've got an brain of\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "max_epochs = 30\n",
    "\n",
    "def train(dataset, model):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        state_h, state_c = model.init_state_batched(batch_size)\n",
    "        \n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            if x.shape[0] != batch_size:\n",
    "                continue # better option: change the size of state_h, state_c, according to the last batch size\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            \n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "                        \n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
    "        print (predict(pooh_dataset, model, 'and then'))\n",
    "        model.train()\n",
    "            \n",
    "train(pooh_dataset, model)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ad0a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'pooh_2x512_30ep_2023.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38520dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(dataset, model, text, next_words=15):\n",
    "    model.eval()\n",
    "\n",
    "    words = word_tokenize(text.lower())\n",
    "    state_h, state_c = model.init_state_unbatched()\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([dataset.word_to_index[w] for w in words[i:]])\n",
    "        x = x.to(device)\n",
    "        \n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[-1] / 0.001\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d7f8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am tired pooh , who was n't quite sure about a little smackerel of something , and then he thought that perhaps he had been a little while ago , and he was so excited that he had been opening and said `` yes , yes , '' said pooh , `` i\n",
      "\n",
      "i am tired piglet , `` i think it was a very particular animal that it was a very good thing to do , but it was a very good thing to do , but it was a very good thing to do , but it was a good thing to do , but\n",
      "\n",
      "i am tired christopher robin , who was just beginning to think , '' said pooh , `` i am not quite sure , '' said pooh , `` i am not quite sure , '' said pooh , `` i am not quite sure , '' said pooh , `` i am not quite\n",
      "\n",
      "i am tired rabbit , `` i shall have to go on , `` i am not sure , '' said pooh , `` i think it 's a very funny thing , '' said pooh , `` i think it 's a very funny thing , '' said pooh , `` i think\n",
      "\n",
      "i am tired owl , `` i think it 's a very funny thing , '' said pooh , `` i think it 's a very funny thing , '' said pooh , `` i think it 's a very good thing to do , but it was a good thing to do ,\n",
      "\n",
      "i am tired tigger to say something else , and then , with a nod of thanks to the top of the forest , and piglet said , `` i shall go and tell them , '' said pooh , `` i am not quite sure , '' said pooh , `` i am\n",
      "\n",
      "i am tired eeyore . `` i am scerching for a little while he could n't think of anything , and then he thought that perhaps he was going to see owl 's house . it was a very good thing to do , but it was n't , so he began to think\n",
      "\n"
     ]
    }
   ],
   "source": [
    "speakers = ['pooh', 'piglet', 'christopher robin', 'rabbit', 'owl', 'tigger', 'eeyore']\n",
    "\n",
    "for s in speakers:\n",
    "    prompt = 'i am tired ' + s \n",
    "    for i in range(1):\n",
    "        print (predict2(pooh_dataset, model, prompt, 50))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f982e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = model.embedding.weight.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b1b43f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2791"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a939d823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD eeyore\n",
      "     exciting\n",
      "     branches\n",
      "     slowly\n",
      "     fir-cone\n",
      "     spikes\n",
      "\n",
      "WORD tigger\n",
      "     good-morning\n",
      "     portrait\n",
      "     fir-cones\n",
      "     wanting\n",
      "     hill\n",
      "\n",
      "WORD pooh\n",
      "     gloomily\n",
      "     walking\n",
      "     crying\n",
      "     jaws\n",
      "     coming\n",
      "\n",
      "WORD piglet\n",
      "     pop\n",
      "     5.\n",
      "     laugh\n",
      "     up\n",
      "     tiddely-poms\n",
      "\n",
      "WORD long\n",
      "     turned\n",
      "     smile\n",
      "     where\n",
      "     ing\n",
      "     hummy\n",
      "\n",
      "WORD honey\n",
      "     deed\n",
      "     clapped\n",
      "     pin\n",
      "     organize\n",
      "     surface\n",
      "\n",
      "WORD door\n",
      "     revolving\n",
      "     notice-board\n",
      "     ached\n",
      "     gon\n",
      "     gorse-bush\n",
      "\n",
      "WORD silent\n",
      "     w-what\n",
      "     handkerchief\n",
      "     deception\n",
      "     roo's\n",
      "     hurriedly\n",
      "\n",
      "WORD path\n",
      "     downstairs\n",
      "     living\n",
      "     dishes\n",
      "     weight\n",
      "     temporary\n",
      "\n",
      "WORD house\n",
      "     wednesday\n",
      "     helpfully\n",
      "     misses\n",
      "     meekly\n",
      "     buffeted\n",
      "\n",
      "WORD forest\n",
      "     smallest-of-all\n",
      "     glowed\n",
      "     explains\n",
      "     own\n",
      "     sends\n",
      "\n",
      "WORD thought\n",
      "     seat\n",
      "     'help\n",
      "     'all\n",
      "     singers\n",
      "     holding\n",
      "\n",
      "WORD brain\n",
      "     dorsal\n",
      "     forward\n",
      "     usual\n",
      "     sparkle\n",
      "     'help\n",
      "\n",
      "WORD little\n",
      "     pom\n",
      "     awoke\n",
      "     kangas\n",
      "     foot\n",
      "     splashed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def length(a):\n",
    "    return a.dot(a) ** 0.5\n",
    "\n",
    "def cos(a, b):\n",
    "    return a.dot(b) / (length(a) * length(b))\n",
    "\n",
    "def best_line(a, K):\n",
    "    res = [(cos(E[a], E[b]), b) for b in range(len(E)) if b != a]\n",
    "    res.sort(reverse=True)\n",
    "    return [pooh_dataset.index_to_word[i] for (v, i) in res[:K]]\n",
    "\n",
    "special_words = 'eeyore tigger pooh piglet long honey door silent path house forest thought brain little'.split()\n",
    "\n",
    "for w in special_words:\n",
    "    print ('WORD', w)\n",
    "    for b in best_line(pooh_dataset.word_to_index[w], 5):\n",
    "        print ('    ', b)\n",
    "    print ()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea1eb733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict as dd\n",
    "\n",
    "vowels = set(\"aoiuye'\")\n",
    "def devowelize(s):\n",
    "    rv = ''.join(a for a in s if a not in vowels)\n",
    "    if rv:\n",
    "        return rv\n",
    "    return '_'\n",
    "\n",
    "representation = dd(set)\n",
    "\n",
    "for w in pooh_dataset.words:\n",
    "    r = devowelize(w)\n",
    "    representation[r].add(w)\n",
    "    \n",
    "hard_words = set()\n",
    "for r, ws in representation.items():\n",
    "    if len(ws) > 1:\n",
    "        hard_words.update(ws)\n",
    "        \n",
    "print (len(hard_words))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32640900",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(pooh_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m (x\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mPoohDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m---> 35\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords_indexes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m:\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequence_length\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     36\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwords_indexes[index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:index\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(pooh_dataset, batch_size=batch_size)\n",
    "for batch, (x, y) in enumerate(dataloader):\n",
    "    print (x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ccd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4feefe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
