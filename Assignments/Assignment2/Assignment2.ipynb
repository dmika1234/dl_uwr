{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "009406d7-6b9a-4d03-9947-7d67f2ac89c6",
    "colab_type": "text",
    "deepnote_cell_height": 90,
    "deepnote_cell_type": "markdown",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dmika1234/dl_uwr/blob/develop/Assignments/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-10528e06-f6bc-4d22-87ba-44ee389423e2",
    "deepnote_cell_height": 513.59375,
    "deepnote_cell_type": "markdown",
    "id": "CzR6cZvYkyl6"
   },
   "source": [
    "## Assignment 2\n",
    "\n",
    "**Submission deadlines:** \n",
    "- get at least 4 points by Tuesday, 30.03.2023\n",
    "- remaining points: last lab session before or on Tuesday, 06.04.2023\n",
    "\n",
    "**Points:** Aim to get 16 out of 20+ possible points\n",
    "\n",
    "## Submission instructions\n",
    "The class is held on-site in lab rooms. Please prepare you notebook on your computer or anywhere in the cloud (try using DeepNote or Google Colab (preferred since one can get free GPUs there)).\n",
    "Make sure you know all the questions and asnwers, and that the notebook contains results; bfore presentation do `Runtime -> Restart and run all`\n",
    "![Picture title](image-20220302-183151.png)\n",
    "\n",
    "We provide starter code, however you are not required to use it as long as you properly solve the tasks.\n",
    "\n",
    "As always, please submit corrections using GitHub's Pull Requests to https://github.com/rnoxy/dl_uwr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-c9d8b5e1-13d2-492d-9ad6-d82d4419394b",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "id": "eJ7DqCH7NDlC"
   },
   "source": [
    "# Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-48229273-726d-45db-bb12-068773ea6b9c",
    "deepnote_cell_height": 433.421875,
    "deepnote_cell_type": "markdown",
    "id": "YXr1RwyMFITD"
   },
   "source": [
    "\n",
    "## Problem 1 [1p]:\n",
    "\n",
    "Let's see why GPUs are useful in deep learning. Compare matrix multiplication speed for a few matrix shapes when implemented:\n",
    "1. as loops in Python\n",
    "2. using np.einsum\n",
    "3. using numpy on CPU\n",
    "4. using pytorch on CPU\n",
    "5. using pytorch on GPU\n",
    "\n",
    "Finally, consider two square matrices, $A$ and $B$. We have 4 possibilities of multiplying them or their transpositions:\n",
    "1. $AB$\n",
    "2. $A^TB$\n",
    "3. $AB^T$\n",
    "4. $A^TB^T$\n",
    "\n",
    "Which option is the fastest? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-6fcf24af-39f5-4e54-a68e-21493b4f3484",
    "deepnote_cell_height": 313.1875,
    "deepnote_cell_type": "markdown",
    "id": "eQa69LGTaiym"
   },
   "source": [
    "## Problem 2: Stochastic Gradient Descent [3p]\n",
    "\n",
    "We provide below starter code that trains a softmax regression model. Alternatively, implement your own training loop and use it to solve this problem jointly with the next one.\n",
    "\n",
    "Implement the following additions to the SGD code provided:\n",
    "  1. **[1p]** momentum\n",
    "  2. **[1p]** learning rate schedule\n",
    "  3. **[1p]** weight decay, in which we additionally minimize for each weight matrix (but typically not the bias) the sum of its elements squared. One way to implement it is to use the function `model.named_parameters` and select all parameters whose names contain \"`weight`\" rather than \"`bias`\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-08ef04aa-9e94-4455-bddc-b843562afd3f",
    "deepnote_cell_height": 350,
    "deepnote_cell_type": "markdown",
    "id": "YsLt4dGsaosv"
   },
   "source": [
    "## Problem 3: Tuning the Network for MNIST [4p]\n",
    "\n",
    "Tune the following network to reach **validation error rate below 1.9%**.\n",
    "This should result in a **test error rate below 2%**. To\n",
    "tune the network you will need to:\n",
    "1. Choose the number of layers (more than 1, less than 5);\n",
    "2. Choose the number of neurons in each layer (more than 100,\n",
    "    less than 5000);\n",
    "3. Pick proper weight initialization;\n",
    "4. Pick proper learning rate schedule (need to decay over time,\n",
    "    a good range to check on MNIST is about 1e-2 ... 1e-1 at the beginning and\n",
    "    half of that after 10000 batches);\n",
    "5. Pick a momentum constant (probably a constant one will be OK).\n",
    "\n",
    "\n",
    "Please note: there are many hyperparameter settings that give the desired answer, some may require tuning all hyperparameters, some only a few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-1469d97b-d10e-428a-a29a-f6446ffaa579",
    "deepnote_cell_height": 130.796875,
    "deepnote_cell_type": "markdown",
    "id": "YrUQloaln1UA"
   },
   "source": [
    "## Problem 4: Convolutional Network [2p]\n",
    "\n",
    "Use convolutional and max-pooling layers (`Conv2d`, `Max_pool2d` or their functional variants) and (without dropout) get a test error rate below 1.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-c363a8df-405f-4da9-a0ab-59e2fa166b63",
    "deepnote_cell_height": 338.1875,
    "deepnote_cell_type": "markdown",
    "id": "_9DaWUy_atrn"
   },
   "source": [
    "## Problem 5: Dropout [2p]\n",
    "\n",
    "Learn about dropout:\n",
    "\n",
    "- implement a **dropout** layer \n",
    "- or use `nn.Dropout` (then the exercise is worth 1.5 points)\n",
    "\n",
    "and try to train a\n",
    "network getting below 1.5% test error rates with dropout, but no convolutions, or below 1% when dropout is used jointly with convolutions!\n",
    "\n",
    "Remember to turn off dropout during testing, using `model.train()` and `model.eval()`!\n",
    "\n",
    "Hint: Use [torch.nn.functional.dropout](http://pytorch.org/docs/master/nn.html#torch.nn.functional.dropout).\n",
    "\n",
    "Details: http://arxiv.org/pdf/1207.0580.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-b71ece13-36f1-4661-b0c6-3739ba0af279",
    "deepnote_cell_height": 212,
    "deepnote_cell_type": "markdown",
    "id": "mB3T_HuYawyQ"
   },
   "source": [
    "## Problem 6: Data Augmentation [1p]\n",
    "\n",
    "Apply data augmentation methods (e.g. rotations, noise, crops) when training networks on MNIST, to significantly reduce test error rate for your network. You can use functions from the [torchvision.transforms](http://pytorch.org/docs/master/torchvision/transforms.html) module.\n",
    "\n",
    "Please note: when using random transformations during training, make sure they are re-computed in every epoch. Consider applying augmentation either in the training loop or in the `InMemDataLoader`. For the second case, function `InMemDataLoader.__iter__` is a good place to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-9efae45c-dfcb-4687-b7c4-98b007244266",
    "deepnote_cell_height": 226,
    "deepnote_cell_type": "markdown",
    "id": "Af7itFE7a0eY"
   },
   "source": [
    "## Problem 7: Batch Normalization [1p]\n",
    "\n",
    "[Batch Normalization](https://arxiv.org/abs/1502.03167) helps training neural networks because it [normalizes layer activation magnitudes](https://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization.pdf). It typically allows to train networks faster and/or with higher learning rates, lessens the importance\n",
    "of initialization and might eliminate the need for Dropout.\n",
    "\n",
    "Implement Batch Normalization and compare with regular training of MNIST models.\n",
    "\n",
    "Remember to use the batch statistics during model training and to use an average of training batch statistics during model evaluation. For details please consult the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-82d7197f-70be-49e8-8a59-99ea637bf693",
    "deepnote_cell_height": 212,
    "deepnote_cell_type": "markdown",
    "id": "CD1Ke8R4a1-Q"
   },
   "source": [
    "## Problem 8: Norm Constraints [1p]\n",
    "\n",
    "Implement norm constraints, i.e. instead of weight decay, that tries to set all weights to small values, apply a limit on the total\n",
    "norm of connections incoming to a neuron. In our case, this\n",
    "corresponds to clipping the norm of *rows* of weight\n",
    "matrices. An easy way of implementing it is to make a gradient\n",
    "step, then look at the norm of rows and scale down those that are\n",
    "over the threshold (this technique is called \"projected gradient descent\").\n",
    "\n",
    "Please consult the Dropout paper (http://arxiv.org/pdf/1207.0580.pdf) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-c12d33a7-8f7d-4d53-b4f4-23f90b3c17ed",
    "deepnote_cell_height": 181.84375,
    "deepnote_cell_type": "markdown",
    "id": "CL3_e1xCa4YG"
   },
   "source": [
    "## Problem 9: Polyak Averaging [1p]\n",
    "\n",
    "Implement Polyak averaging. For each parameter $\\theta$\n",
    "keep a separate, exponentially decayed average of the past values\n",
    "$$\n",
    "\\bar{\\theta}_n = \\alpha_p\\bar{\\theta}_{n-1} + (1-\\alpha_p)\\theta_n.\n",
    "$$\n",
    "Use that average when evaluating the model on the test set.\n",
    "Validate the approach by training a model on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-9ad9a7b8-4ee0-4df2-8a0c-6ed0cb246cdc",
    "deepnote_cell_height": 198,
    "deepnote_cell_type": "markdown",
    "id": "w7LoH9DIa88J"
   },
   "source": [
    "## Problem 10: Hyperparameter tuner [1p]\n",
    "\n",
    "Implement a hyper-parameter tuner able to optimize the learning rate schedule, number of neurons, and similar hyperparameters. To start, use a random search (please see http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf and especially Fig 1. for intuitions on why random search is better than grid search). It may be a good idea to use a fixed maximum number of epochs (or training time) for each optimization trial to prevent selecting hyperparameters that yield slowly converging solutions. A good result will be a set of hyperparameters that reach on MNIST solutions with test errors less than $1.3\\%$ in no more than 50 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-1bb7d06a-33a4-4e1a-9922-d09becbcbddb",
    "deepnote_cell_height": 464.390625,
    "deepnote_cell_type": "markdown",
    "id": "mzJTDu2aE8sk"
   },
   "source": [
    "## Problem 11: Pruning [1p]\n",
    "\n",
    "Prune the MNIST network to retain validation accuracy no worse than 0.1 percentage point at maximum sparsity (maximal number of weights removed from the network).\n",
    "\n",
    "One way to do it is to \n",
    "1. train the network, \n",
    "2. set to zero the smallest weights (typically you can zero up to 50% of weights)\n",
    "3. retrain the network, keeping the zeroed weights zeroed, and repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-bfe2d2f2-2578-47ee-9112-5f72785b0778",
    "deepnote_cell_height": 212,
    "deepnote_cell_type": "markdown",
    "id": "7jyEkvsqo2bx"
   },
   "source": [
    "## Problem 12: Extreme Learning Machine (ELM) [2p]\n",
    "\n",
    "Consider a neural network with 1 hidden layer. In the extreme learning approach, the first layer is not trained, but instead, it is randomly set. It is often very large. The second (output) layer weights can then be set using the closed-form formula for linear regression. Thus, training an ELM is fast (there is no iterative optimization) and one can try many different hyperparameters, such as hidden layer size, the random distribution from which weights are sampled, the hidden activation function, and so forth.\n",
    "\n",
    "Task: Implement an ELM for MNIST and try to reach the performance of your backpropagation-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-f8cf66c4-94bb-492c-abb5-845f0be43678",
    "deepnote_cell_height": 130.796875,
    "deepnote_cell_type": "markdown",
    "id": "aotfN2N2FCM6"
   },
   "source": [
    "## Problem 13: Other tricks [1p-many]\n",
    "\n",
    "The neural network literature is full of tricks for training neural networks. Find some and implement them. Please note: the number of points depends on the hardness of the extension you want to implement. If in doubt, consult the TA beforehand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-c2f60d20-e061-443c-a8e3-1713b5192445",
    "deepnote_cell_height": 120.390625,
    "deepnote_cell_type": "markdown",
    "id": "NNfw6pY9sRJe"
   },
   "source": [
    "# Starter code\n",
    "\n",
    "The code below trains a SoftMax regression model in PyTorch. It can easily be extended into a full multilayer neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00017-cf2d5c0e-2979-4394-9d7b-26cf2d6f6225",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "id": "iEUPZksWm9YU"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 2\n",
    "alpha0 = alpha\n",
    "alpha = 3\n",
    "alpha0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.normal(size=(500, 500))\n",
    "B = np.random.normal(size=(500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 20s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# start = time.time()\n",
    "result = [] # final result\n",
    "for i in range(len(A)):\n",
    "\n",
    "    row = [] # the new row in new matrix\n",
    "    for j in range(len(B[0])):\n",
    "        \n",
    "        product = 0 # the new element in the new row\n",
    "        for v in range(len(A[i])):\n",
    "            product += A[i][v] * B[v][j]\n",
    "        row.append(product) # append sum of product into the new row\n",
    "        \n",
    "    result.append(row) # append the new row into the final result\n",
    "# stop = time.time()\n",
    "# print(f'Time taken to multiply A and B: {stop - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 74.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = np.einsum('ij, jk ->ik', A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = np.dot(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_t = torch.from_numpy(A)\n",
    "B_t = torch.from_numpy(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 4.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = torch.matmul(A_t, B_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "A_t = A_t.to(device)\n",
    "B_t = B_t.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = torch.matmul(A_t, B_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = np.dot(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 4.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = np.dot(A.T, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = np.dot(A.T, B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 998 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = np.dot(A, B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00019-ef919890-5be1-4bbd-9b4b-3bfb1aefee40",
    "deepnote_cell_height": 732,
    "deepnote_cell_type": "code",
    "id": "tPOMFqLZsfuj"
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(model, data_loader, device=\"cpu\"):\n",
    "    \"\"\"Evaluate model on all samples from the data loader.\n",
    "    \"\"\"\n",
    "    # Put the model in eval mode, and move to the evaluation device.\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    if isinstance(data_loader, InMemDataLoader):\n",
    "        data_loader.to(device)\n",
    "\n",
    "    num_errs = 0.0\n",
    "    num_examples = 0\n",
    "    # we don't need gradient during eval!\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            outputs = model.forward(x)\n",
    "            _, predictions = outputs.data.max(dim=1)\n",
    "            num_errs += (predictions != y.data).sum().item()\n",
    "            num_examples += x.size(0)\n",
    "    return num_errs / num_examples\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"Helper to plot the trainig progress over time.\"\"\"\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    train_loss = np.array(history[\"train_losses\"])\n",
    "    plt.semilogy(np.arange(train_loss.shape[0]), train_loss, label=\"batch train loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    train_errs = np.array(history[\"train_errs\"])\n",
    "    plt.plot(np.arange(train_errs.shape[0]), train_errs, label=\"batch train error rate\")\n",
    "    val_errs = np.array(history[\"val_errs\"])\n",
    "    plt.plot(val_errs[:, 0], val_errs[:, 1], label=\"validation error rate\", color=\"r\")\n",
    "    plt.ylim(0, 0.20)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-12705b84-2e28-4596-878c-69510f5bf058",
    "deepnote_cell_height": 130.796875,
    "deepnote_cell_type": "markdown",
    "id": "OT6R09JnnYs9"
   },
   "source": [
    "## Data loading\n",
    "\n",
    "Training speed is important. By default, data is loaded on the CPU, then shipped in batches to the GPU. For this exercise, we will load the full dataset onto the GPU, which speeds up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00021-b3c4901d-b2c9-400d-84d3-667224735d7d",
    "deepnote_cell_height": 1362,
    "deepnote_cell_type": "code",
    "id": "OPh9uR8ZorL7"
   },
   "outputs": [],
   "source": [
    "class InMemDataLoader(object):\n",
    "    \"\"\"\n",
    "    A data loader that keeps all data in CPU or GPU memory.\n",
    "    \"\"\"\n",
    "\n",
    "    __initialized = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        sampler=None,\n",
    "        batch_sampler=None,\n",
    "        drop_last=False,\n",
    "    ):\n",
    "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
    "        batches = []\n",
    "        for i in tqdm(range(len(dataset))):\n",
    "            batch = [torch.tensor(t) for t in dataset[i]]\n",
    "            batches.append(batch)\n",
    "        tensors = [torch.stack(ts) for ts in zip(*batches)]\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "        if batch_sampler is not None:\n",
    "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
    "                raise ValueError(\n",
    "                    \"batch_sampler option is mutually exclusive \"\n",
    "                    \"with batch_size, shuffle, sampler, and \"\n",
    "                    \"drop_last\"\n",
    "                )\n",
    "            self.batch_size = None\n",
    "            self.drop_last = None\n",
    "\n",
    "        if sampler is not None and shuffle:\n",
    "            raise ValueError(\"sampler option is mutually exclusive with \" \"shuffle\")\n",
    "\n",
    "        if batch_sampler is None:\n",
    "            if sampler is None:\n",
    "                if shuffle:\n",
    "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
    "                else:\n",
    "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "            batch_sampler = torch.utils.data.BatchSampler(\n",
    "                sampler, batch_size, drop_last\n",
    "            )\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.__initialized = True\n",
    "\n",
    "    def __setattr__(self, attr, val):\n",
    "        if self.__initialized and attr in (\"batch_size\", \"sampler\", \"drop_last\"):\n",
    "            raise ValueError(\n",
    "                \"{} attribute should not be set after {} is \"\n",
    "                \"initialized\".format(attr, self.__class__.__name__)\n",
    "            )\n",
    "\n",
    "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_indices in self.batch_sampler:\n",
    "            yield self.dataset[batch_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "\n",
    "    def to(self, device):\n",
    "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00023-1ae08eac-ed89-46d5-b212-29029275d401",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "f812ea5e8de34f13b6d77523bd59619b",
      "27d7e1ef4252482ebd054155383ef73c",
      "cd6c38cfe20a453b9890b91e379f6adb",
      "f9ab073ef44d4d1190e6c16897effe36",
      "89d18bcff5b4416fa2ebf7ecf5e576bf",
      "7064e43a34b945dca49470e1eb118469",
      "32b37b209d61481e8a5dd656f639f221",
      "52d8ab18c3f34643aa1f07add6180714",
      "fd0c0b007c854d00a4432f5d5004b70f",
      "beca25b53ebe467caa02205b094b19a1",
      "6105dc20b88c4508958c9b0baa459b23",
      "fc2532f430c74268a8541613b1acc2df",
      "817a42f342eb4d02ba2072ad90d7c5bb",
      "98fe0324eeb346a6ad37ffc8ba75d58d",
      "b53524197a3d401ead0a99318bd6ec0c",
      "286f1846c16f4d988222e0d7d7f2a05a",
      "ffa6fe99547c487397510794b8ddd192",
      "a3eb493e14334d2c8812c6b23013948a",
      "b624c5832e76473285cc4ceb5b964be2",
      "f6f9b7644453421cb44cb7323a30a372",
      "845e278821bf42f89d3d84df8e297aee",
      "6e8b5b619d114e28a67232b9754c9d67",
      "04cf131f657340efb0b4e19fe2e3e049",
      "33639dd21074403c821b7025f337aaf2"
     ]
    },
    "deepnote_cell_height": 1054.796875,
    "deepnote_cell_type": "code",
    "id": "wDM2KTPQm8V3",
    "outputId": "e92434b9-18e4-4396-efad-3080a73bdbb9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc012242dcd47da8afa762135bf5486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmika\\AppData\\Local\\Temp\\ipykernel_6348\\2199848925.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = [torch.tensor(t) for t in dataset[i]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e6c79e358c4366ad9e283e43c32777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773db18f3d534a8583343d197354bb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "batch_size = 128\n",
    "data_path = \"./data\"\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "_test = torchvision.datasets.MNIST(\n",
    "    data_path, train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Load training data, split into train and valid sets\n",
    "_train = torchvision.datasets.MNIST(\n",
    "    data_path, train=True, download=True, transform=transform\n",
    ")\n",
    "_train.data = _train.data[:50000]\n",
    "_train.targets = _train.targets[:50000]\n",
    "\n",
    "_valid = torchvision.datasets.MNIST(\n",
    "    data_path, train=True, download=True, transform=transform\n",
    ")\n",
    "_valid.data = _valid.data[50000:]\n",
    "_valid.targets = _valid.targets[50000:]\n",
    "\n",
    "mnist_loaders = {\n",
    "    \"train\": InMemDataLoader(_train, batch_size=batch_size, shuffle=True),\n",
    "    \"valid\": InMemDataLoader(_valid, batch_size=batch_size, shuffle=False),\n",
    "    \"test\": InMemDataLoader(_test, batch_size=batch_size, shuffle=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-481f7a8f-3abb-4f8f-aaba-951e8e06aafc",
    "deepnote_cell_height": 108.390625,
    "deepnote_cell_type": "markdown",
    "id": "rRYr7XmnnGO_"
   },
   "source": [
    "## SGD implementation\n",
    "\n",
    "We provide below a scaffolding for SGD. You will need to fill the TODOs while solving the assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00025-2145e55b-7562-438c-bce3-8720962f9bfb",
    "deepnote_cell_height": 2460,
    "deepnote_cell_type": "code",
    "id": "WY1xG-cqnRoE"
   },
   "outputs": [],
   "source": [
    "def SGD(\n",
    "    model,\n",
    "    data_loaders,\n",
    "    alpha=1e-4,\n",
    "    epsilon=0.0,\n",
    "    decay=0.0,\n",
    "    num_epochs=1,\n",
    "    max_num_epochs=np.nan,\n",
    "    patience_expansion=1.5,\n",
    "    log_every=100,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "\n",
    "    # Put the model in train mode, and move to the evaluation device.\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for data_loader in data_loaders.values():\n",
    "        if isinstance(data_loader, InMemDataLoader):\n",
    "            data_loader.to(device)\n",
    "\n",
    "    #\n",
    "    # TODO for Problem 1.3: Initialize momentum variables\n",
    "    # Hint: You need one velocity matrix for each parameter\n",
    "    #\n",
    "    velocities = [None for _ in model.parameters()]\n",
    "    #\n",
    "    iter_ = 0\n",
    "    epoch = 0\n",
    "    best_params = None\n",
    "    best_val_err = np.inf\n",
    "    history = {\"train_losses\": [], \"train_errs\": [], \"val_errs\": []}\n",
    "    print(\"Training the model!\")\n",
    "    print(\"Interrupt at any time to evaluate the best validation model so far.\")\n",
    "    try:\n",
    "        tstart = time.time()\n",
    "        siter = iter_\n",
    "        while epoch < num_epochs:\n",
    "            model.train()\n",
    "            epoch += 1\n",
    "            if epoch > max_num_epochs:\n",
    "                break\n",
    "            #\n",
    "            # TODO: You can implement learning rate control here (it is updated\n",
    "            # once per epoch), or below in the loop over minibatches.\n",
    "            #\n",
    "            \n",
    "            for x, y in data_loaders[\"train\"]:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                iter_ += 1\n",
    "                # This calls the `forward` function: https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html\n",
    "                out = model(x)\n",
    "                loss = model.loss(out, y)\n",
    "                loss.backward()\n",
    "                _, predictions = out.max(dim=1)\n",
    "                batch_err_rate = (predictions != y).sum().item() / out.size(0)\n",
    "\n",
    "                history[\"train_losses\"].append(loss.item())\n",
    "                history[\"train_errs\"].append(batch_err_rate)\n",
    "\n",
    "                # disable gradient computations - we do not want torch to\n",
    "                # backpropagate through the gradient application!\n",
    "                with torch.no_grad():\n",
    "                    for (name, p), v in zip(model.named_parameters(), velocities):\n",
    "                        if \"weight\" in name:\n",
    "                            #\n",
    "                            # TODO for Problem 1.3: Implement weight decay (L2 regularization\n",
    "                            # on weights by changing the gradients\n",
    "                            # p.grad += TODO\n",
    "                            #\n",
    "                            pass\n",
    "\n",
    "                        #\n",
    "                        # TODO for Problem 1.2: Implement a learning rate schedule\n",
    "                        # Hint: You can use the iteration or epoch counters\n",
    "                        # alpha = TODO\n",
    "                        #\n",
    "\n",
    "                        #\n",
    "                        # TODO for Problem 1.1: If needed, implement here a momentum schedule\n",
    "                        # epsilon = TODO\n",
    "                        #\n",
    "\n",
    "                        #\n",
    "                        # TODO for Problem 1.1: Implement velocity updates for momentum\n",
    "                        # lease make sure to modify the contents of v, not the v pointer!!!\n",
    "                        #\n",
    "                        # v[...] = TODO\n",
    "\n",
    "                        #\n",
    "                        # TODO for Problem 1: Set a more sensible learning rule here,\n",
    "                        #       using your learning rate schedule and momentum\n",
    "                        #\n",
    "                        p -= alpha * p.grad\n",
    "\n",
    "                        # Zero gradients for the next iteration\n",
    "                        p.grad.zero_()\n",
    "\n",
    "                if iter_ % log_every == 0:\n",
    "                    num_iter = iter_ - siter + 1\n",
    "                    print(\n",
    "                        \"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%, steps/s {3: >5.2f}\".format(\n",
    "                            iter_,\n",
    "                            loss.item(),\n",
    "                            batch_err_rate * 100.0,\n",
    "                            num_iter / (time.time() - tstart),\n",
    "                        )\n",
    "                    )\n",
    "                    tstart = time.time()\n",
    "\n",
    "            val_err_rate = compute_error_rate(model, data_loaders[\"valid\"], device)\n",
    "            history[\"val_errs\"].append((iter_, val_err_rate))\n",
    "\n",
    "            if val_err_rate < best_val_err:\n",
    "                # Adjust num of epochs\n",
    "                num_epochs = int(np.maximum(num_epochs, epoch * patience_expansion + 1))\n",
    "                best_epoch = epoch\n",
    "                best_val_err = val_err_rate\n",
    "                best_params = [p.detach().cpu() for p in model.parameters()]\n",
    "            clear_output(True)\n",
    "            m = \"After epoch {0: >2} | valid err rate: {1: >5.2f}% | doing {2: >3} epochs\".format(\n",
    "                epoch, val_err_rate * 100.0, num_epochs\n",
    "            )\n",
    "            print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    if best_params is not None:\n",
    "        print(\"\\nLoading best params on validation set (epoch %d)\\n\" % (best_epoch))\n",
    "        with torch.no_grad():\n",
    "            for param, best_param in zip(model.parameters(), best_params):\n",
    "                param[...] = best_param\n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00026-06863917-ddb1-425f-9d6e-93c06b30e87b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "deepnote_cell_height": 1464.5625,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     249.5,
     251.078125
    ],
    "id": "2gmDmR2K6CVQ",
    "outputId": "4744390f-6966-4514-bf06-6940d6c1b336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "After epoch 30 | valid err rate:  8.63% | doing  46 epochs\n",
      "----------------------------------------------------------\n",
      "\n",
      "Loading best params on validation set (epoch 30)\n",
      "\n",
      "------------------------------------------\n",
      "Test error rate: 9.150%, training took 9s.\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Model, self).__init__()\n",
    "        self.layers = nn.Sequential(*args, **kwargs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(X.size(0), -1)\n",
    "        return self.layers.forward(X)\n",
    "\n",
    "    def loss(self, Out, Targets):\n",
    "        return F.cross_entropy(Out, Targets)\n",
    "\n",
    "\n",
    "model = Model(nn.Linear(28 * 28, 10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Initialize parameters\n",
    "    for name, p in model.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            p.normal_(0, 0.5)\n",
    "        elif \"bias\" in name:\n",
    "            p.zero_()\n",
    "        else:\n",
    "            raise ValueError('Unknown parameter name \"%s\"' % name)\n",
    "\n",
    "# On GPU enabled devices set device='cuda' else set device='cpu'\n",
    "t_start = time.time()\n",
    "SGD(model, mnist_loaders, alpha=1e-1, max_num_epochs=30, device='cpu')\n",
    "\n",
    "\n",
    "test_err_rate = compute_error_rate(model, mnist_loaders[\"test\"])\n",
    "m = (\n",
    "    f\"Test error rate: {test_err_rate * 100.0:.3f}%, \"\n",
    "    f\"training took {time.time() - t_start:.0f}s.\"\n",
    ")\n",
    "print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Assignment2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ffaf5b3e-ad2e-45f4-b61f-77edfc82388b",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04cf131f657340efb0b4e19fe2e3e049": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27d7e1ef4252482ebd054155383ef73c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "286f1846c16f4d988222e0d7d7f2a05a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32b37b209d61481e8a5dd656f639f221": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33639dd21074403c821b7025f337aaf2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52d8ab18c3f34643aa1f07add6180714": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6105dc20b88c4508958c9b0baa459b23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98fe0324eeb346a6ad37ffc8ba75d58d",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_817a42f342eb4d02ba2072ad90d7c5bb",
      "value": 10000
     }
    },
    "6e8b5b619d114e28a67232b9754c9d67": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7064e43a34b945dca49470e1eb118469": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "817a42f342eb4d02ba2072ad90d7c5bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "845e278821bf42f89d3d84df8e297aee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "89d18bcff5b4416fa2ebf7ecf5e576bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "98fe0324eeb346a6ad37ffc8ba75d58d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3eb493e14334d2c8812c6b23013948a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b53524197a3d401ead0a99318bd6ec0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b624c5832e76473285cc4ceb5b964be2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e8b5b619d114e28a67232b9754c9d67",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_845e278821bf42f89d3d84df8e297aee",
      "value": 10000
     }
    },
    "beca25b53ebe467caa02205b094b19a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd6c38cfe20a453b9890b91e379f6adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7064e43a34b945dca49470e1eb118469",
      "max": 50000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89d18bcff5b4416fa2ebf7ecf5e576bf",
      "value": 50000
     }
    },
    "f6f9b7644453421cb44cb7323a30a372": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33639dd21074403c821b7025f337aaf2",
      "placeholder": "​",
      "style": "IPY_MODEL_04cf131f657340efb0b4e19fe2e3e049",
      "value": " 10000/10000 [02:08&lt;00:00, 77.73it/s]"
     }
    },
    "f812ea5e8de34f13b6d77523bd59619b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd6c38cfe20a453b9890b91e379f6adb",
       "IPY_MODEL_f9ab073ef44d4d1190e6c16897effe36"
      ],
      "layout": "IPY_MODEL_27d7e1ef4252482ebd054155383ef73c"
     }
    },
    "f9ab073ef44d4d1190e6c16897effe36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52d8ab18c3f34643aa1f07add6180714",
      "placeholder": "​",
      "style": "IPY_MODEL_32b37b209d61481e8a5dd656f639f221",
      "value": " 50000/50000 [00:08&lt;00:00, 5595.16it/s]"
     }
    },
    "fc2532f430c74268a8541613b1acc2df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_286f1846c16f4d988222e0d7d7f2a05a",
      "placeholder": "​",
      "style": "IPY_MODEL_b53524197a3d401ead0a99318bd6ec0c",
      "value": " 10000/10000 [02:10&lt;00:00, 76.82it/s]"
     }
    },
    "fd0c0b007c854d00a4432f5d5004b70f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6105dc20b88c4508958c9b0baa459b23",
       "IPY_MODEL_fc2532f430c74268a8541613b1acc2df"
      ],
      "layout": "IPY_MODEL_beca25b53ebe467caa02205b094b19a1"
     }
    },
    "ffa6fe99547c487397510794b8ddd192": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b624c5832e76473285cc4ceb5b964be2",
       "IPY_MODEL_f6f9b7644453421cb44cb7323a30a372"
      ],
      "layout": "IPY_MODEL_a3eb493e14334d2c8812c6b23013948a"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
